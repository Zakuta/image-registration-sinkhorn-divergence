{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mandatory Imports from auxiliary libraries and custom implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd        import grad\n",
    "from pykeops.torch         import Kernel\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "from scipy import misc\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from matplotlib import pyplot as plt\n",
    "from time import time\n",
    "import extract_coordinates_json as json_coord\n",
    "import extract_svg_coordinates as svg_coord\n",
    "from statsmodels import robust\n",
    "from common.sinkhorn_balanced import sinkhorn_divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deciding to whether use CUDA (GPU) or normal Float Tensor of PyTorch and defining raw path files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "tensor   = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "\n",
    "plt.ion()\n",
    "plt.show()\n",
    "\n",
    "s2v = lambda x: tensor([x])\n",
    "\n",
    "svg_path_shape1 = r'/home/yash/Desktop/HaTran/Shape1_start_absolute.svg'\n",
    "svg_path_shape2 = r'/home/yash/Desktop/HaTran/Shape2_start_absolute.svg'\n",
    "svg_path_shape3 = r'/home/yash/Desktop/HaTran/Shape3_start_absolute.svg'\n",
    "\n",
    "json_path = r'/home/yash/Desktop/HaTran/patient_data.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining what kind of routines to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = {}\n",
    "\n",
    "if True:  # Sinkhorn\n",
    "    for p in [2]:  # C(x,y) = |x-y|^1 or |x-y|^2\n",
    "        for eps, eps_s in [(.01, \"S\")]:\n",
    "            for nits in [2]:\n",
    "                experiments[\"sinkhorn_L{}_{}_{}its\".format(p, eps_s, nits)] = {\n",
    "                    \"formula\": \"sinkhorn\",\n",
    "                    \"p\": p,\n",
    "                    \"eps\": eps ** p,  # Remember : eps is homogeneous to C(x,y)\n",
    "                    \"nits\": nits,\n",
    "                    \"tol\": 0.,  # Run all iterations, no early stopping!\n",
    "                    \"transport_plan\": \"heatmaps\",\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading an image (png) as a PyTorch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadImage(fname):\n",
    "    img = misc.imread(fname, flatten = True)    # Grayscale\n",
    "    img = gaussian_filter(img, 1, mode='nearest')    # Applying Gaussian filter to blur the image which would \n",
    "                                                     # smoothen the image and will be of great help while using\n",
    "                                                     # autodifferentiaition as smooth gradients tend to good converegence.\n",
    "#     plt.imshow(img)\n",
    "    img = (img[::-1,:]) / 255.      # Normalizing the image\n",
    "    img = np.swapaxes(img, 0, 1)    # Taking transpose as tensors are always stored as transpose (column vectors) of a function\n",
    "    return tensor (1 - img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and some Macros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"shape\"\n",
    "datasets = {\n",
    "    \"shape\": (\"data/patient_input_0.png\", \"data/shape1.png\"),\n",
    "}\n",
    "    \n",
    "\n",
    "# Note that both measures will be normalized in \"sparse_distance_bmp\"\n",
    "source = LoadImage(datasets[dataset][0])\n",
    "target = LoadImage(datasets[dataset][1])\n",
    "\n",
    "print(source.shape)\n",
    "\n",
    "# The images are rescaled to fit into the unit square \n",
    "scale = source.shape[0]\n",
    "affine = tensor([[1, 0, 0], [0, 1, 0]]) / scale\n",
    "\n",
    "# We'll save the output wrt. the number of iterations\n",
    "display = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting a Point Cloud of an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_point_cloud(I, affine):\n",
    "\n",
    "    # Threshold, to extract the relevant indices \n",
    "    ind = (I > .001).nonzero()\n",
    "    \n",
    "    # Extract the weights \n",
    "    D = len(I.shape)\n",
    "    if   D == 2 : α_i = I[ind[:,0], ind[:,1]]    # weights of the non-zero pixel indices\n",
    "    elif D == 3 : α_i = I[ind[:,0], ind[:,1], ind[:,2]]    # weights of the non-zero pixel indices\n",
    "    else : raise NotImplementedError()\n",
    "\n",
    "    α_i = α_i * affine[0, 0] * affine[1, 1] # Lazy approximation of the determinant...\n",
    "    # If we normalize the measures, it doesn't matter anyway.\n",
    "\n",
    "    # Don't forget the changes of coordinates! \n",
    "    M   = affine[:D,:D] ; off = affine[:D,D]\n",
    "    x_i = ind.float() @ M.t() + off\n",
    "\n",
    "    return ind, α_i.view(-1, 1), x_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to calculate the sparse distance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_distance_bmp(params, A, B, affine_A, affine_B, normalize=True, info=False, action=\"measure\"):\n",
    "    \"\"\"\n",
    "    Takes as input two torch bitmaps (Tensors). \n",
    "    Returns a cost and a gradient, encoded as a vector bitmap.\n",
    "\n",
    "    Args :\n",
    "        - A and B : two torch bitmaps (Tensors) of dimension D.\n",
    "        - affine_A and affine_B : two matrices of size (D+1,D+1) (Tensors).\n",
    "    \"\"\"\n",
    "    D = len(A.shape) # dimension of the ambient space, =2 for slices or =3 for volumes\n",
    "\n",
    "    ind_A, α_i, x_i = extract_point_cloud(A, affine_A)\n",
    "    ind_B, β_j, y_j = extract_point_cloud(B, affine_B)\n",
    "\n",
    "    if normalize :\n",
    "        α_i = α_i / α_i.sum()\n",
    "        β_j = β_j / β_j.sum()\n",
    "\n",
    "    x_i.requires_grad = True\n",
    "    if action == \"image\" :\n",
    "        α_i.requires_grad = True\n",
    "\n",
    "    # Compute the distance between the *measures* A and B ------------------------------\n",
    "    # print(\"{:,}-by-{:,} KP: \".format(len(x_i), len(y_j)), end='')\n",
    "\n",
    "    routines = { \n",
    "        \"sinkhorn\"       : sinkhorn_divergence,    # This is blindly copied from the implementation \n",
    "                                                   # done by the authors.  \n",
    "    }\n",
    "\n",
    "    routine = routines[ params.get(\"formula\", \"sinkhorn\") ]\n",
    "    params[\"heatmaps\"] = info\n",
    "    cost, heatmaps = routine( α_i,x_i, β_j,y_j, **params )\n",
    "\n",
    "    if action == \"image\" :\n",
    "        grad_a, grad_x = grad( cost, [α_i, x_i] ) # gradient wrt the voxels' positions and weights\n",
    "    elif action == \"measure\" :\n",
    "        grad_x = grad( cost, [x_i] )[0] # gradient wrt the voxels' positions\n",
    "\n",
    "    # Point cloud to bitmap (grad_x) ---------------------------------------------------\n",
    "    tensor   = torch.cuda.FloatTensor if A.is_cuda else torch.FloatTensor \n",
    "    # Using torch.zero(...).dtype(cuda.FloatTensor) would be inefficient...\n",
    "    # Let's directly make a \"malloc\", before zero-ing in place\n",
    "    grad_A = tensor( *(tuple(A.shape) + (D,))  )\n",
    "    grad_A.zero_()\n",
    "\n",
    "    if action == \"measure\":\n",
    "        if D == 2:\n",
    "            grad_A[ind_A[:, 0], ind_A[:, 1], :] = grad_x[:, :]\n",
    "        elif D == 3:\n",
    "            grad_A[ind_A[:, 0], ind_A[:, 1], ind_A[:, 2], :] = grad_x[:, :]\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "\n",
    "    elif action == \"image\":\n",
    "        if D == 2:\n",
    "            if True:\n",
    "                dim_0 = affine_A[0,0]; print(dim_0)\n",
    "                grad_A[ind_A[:, 0], ind_A[:,1], :] += .25 * dim_0 * grad_x[:,:]\n",
    "                grad_A[ind_A[:, 0] + 1, ind_A[:, 1], :] += .25 * dim_0 * grad_x[:,:]\n",
    "                grad_A[ind_A[:, 0], ind_A[:,1]+1, :] += .25 * dim_0 * grad_x[:,:]\n",
    "                grad_A[ind_A[:, 0] + 1, ind_A[:, 1] + 1, :] += .25 * dim_0 * grad_x[:,:]\n",
    "\n",
    "            grad_a = grad_a[:] * α_i[:]\n",
    "            grad_A[ind_A[:,0]  ,ind_A[:,1]  , 0] -= .5*grad_a[:]\n",
    "            grad_A[ind_A[:,0]+1,ind_A[:,1]  , 0] += .5*grad_a[:]\n",
    "            grad_A[ind_A[:,0]  ,ind_A[:,1]+1, 0] -= .5*grad_a[:]\n",
    "            grad_A[ind_A[:,0]+1,ind_A[:,1]+1, 0] += .5*grad_a[:]\n",
    "\n",
    "            grad_A[ind_A[:,0]  ,ind_A[:,1]  , 1] -= .5*grad_a[:]\n",
    "            grad_A[ind_A[:,0]  ,ind_A[:,1]+1, 1] += .5*grad_a[:]\n",
    "            grad_A[ind_A[:,0]+1,ind_A[:,1]  , 1] -= .5*grad_a[:]\n",
    "            grad_A[ind_A[:,0]+1,ind_A[:,1]+1, 1] += .5*grad_a[:]\n",
    " \n",
    "            if False :\n",
    "                grad_A[ind_A[:,0]  ,ind_A[:,1]  , 0] = grad_a[:]\n",
    "                grad_A[ind_A[:,0]  ,ind_A[:,1]  , 1] = grad_a[:]\n",
    "            \n",
    "    # N.B.: we return \"PLUS gradient\", i.e. \"MINUS a descent direction\".\n",
    "    return cost, grad_A.detach(), heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score(name, params):\n",
    "    t_0 = time()\n",
    "    cost, grad_src, heatmaps = sparse_distance_bmp(params, source, target, \n",
    "                                                           affine, affine, \n",
    "                                                           normalize=True, info=display )\n",
    "    t_1 = time()\n",
    "    \n",
    "    return float(\"{:.6f}\".format(cost.item())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, params in experiments.items():\n",
    "    cost = calculate_score(name=name, params=params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
